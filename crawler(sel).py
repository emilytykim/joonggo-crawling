# crawler.py

import time
import csv
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import os


def get_post_links(driver, category_url, max_pages=50):
    """
    ê²Œì‹œíŒ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ì—ì„œ ê¸€ ì œëª©, URL, ì‘ì„±ì¼, ë‹‰ë„¤ì„ ìˆ˜ì§‘
    """
    driver.get(category_url)
    time.sleep(2)

    posts = []
    current_page = 1

    while current_page <= max_pages:
        print(f"ğŸ“„ Page {current_page}")
        time.sleep(1)

        try:
            post_rows = driver.find_elements(By.CSS_SELECTOR, "#cafe_content .article-board table tbody tr")

            for row in post_rows:
                try:
                    title_elem = row.find_element(By.CSS_SELECTOR, "td.td_article a.article")
                    date_elem = row.find_element(By.CSS_SELECTOR, "td.td_date")
                    nick_elem = row.find_element(By.CSS_SELECTOR, "td.p-nick a.m-tcol-c")

                    posts.append({
                        "title": title_elem.text.strip(),
                        "url": title_elem.get_attribute("href"),
                        "date": date_elem.text.strip(),
                        "nickname": nick_elem.text.strip()
                    })

                except Exception:
                    continue

            # ë‹¤ìŒ í˜ì´ì§€ ë²„íŠ¼ í´ë¦­
            next_button_xpath = f"//button[@class='btn number' and text()='{(current_page % 10) or 10}']"
            try:
                next_btn = WebDriverWait(driver, 3).until(
                    EC.element_to_be_clickable((By.XPATH, next_button_xpath))
                )
                next_btn.click()
                current_page += 1
            except:
                print("â›”ï¸ ë” ì´ìƒ í˜ì´ì§€ ì—†ìŒ")
                break

            # 10ë²ˆì§¸ í˜ì´ì§€ë§ˆë‹¤ â†’ í™”ì‚´í‘œ ëˆŒëŸ¬ì„œ 11, 21, ...ë¡œ ì´ë™
            if current_page % 10 == 1 and current_page != 1:
                try:
                    arrow_btn = driver.find_element(By.CSS_SELECTOR, ".Pagination .btn.type_next")
                    arrow_btn.click()
                    time.sleep(1)
                except:
                    break

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break

    return posts


def get_post_details(driver, post):
    """
    ìƒì„¸í˜ì´ì§€ ì§„ì…í•´ì„œ ê°€ê²©, íŒë§¤ìƒíƒœ ì¶”ì¶œ
    """
    try:
        driver.get(post["url"])
        time.sleep(1)

        # ê°€ê²© ì¶”ì¶œ
        price_elem = WebDriverWait(driver, 3).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "strong.cost"))
        )
        post["price"] = price_elem.text.strip()

        # íŒë§¤ìƒíƒœ ì¶”ì¶œ
        try:
            status_elem = driver.find_element(By.CSS_SELECTOR, "em.SaleLabel")
            post["status"] = status_elem.text.strip()
        except:
            post["status"] = "íŒë§¤ì¤‘"

    except Exception as e:
        print(f"âŒ ìƒì„¸ í˜ì´ì§€ ì˜¤ë¥˜: {post['url']} | {e}")
        post["price"] = "N/A"
        post["status"] = "N/A"

    return post


def crawl_category(category_name, category_url, output_csv, max_pages=50):
    """
    ì¹´í…Œê³ ë¦¬ ì „ì²´ ìˆœíšŒ í¬ë¡¤ë§
    """
    print(f"ğŸš€ Start crawling: {category_name}")

    # ì„¸ì…˜ ìœ ì§€í•˜ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ì— user-data-dir ì¶”ê°€
    options = Options()
    options.add_argument("--start-maximized")
    # options.add_argument("--user-data-dir=/Users/yourname/Library/Application Support/Google/Chrome")

    driver = webdriver.Chrome(options=options)

    try:
        post_links = get_post_links(driver, category_url, max_pages)

        all_data = []
        for idx, post in enumerate(post_links, 1):
            print(f"ğŸ” ({idx}/{len(post_links)}) ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘...")
            result = get_post_details(driver, post)
            all_data.append(result)

        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(output_csv), exist_ok=True)

        # CSV ì €ì¥
        with open(output_csv, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=["title", "url", "date", "nickname", "price", "status"])
            writer.writeheader()
            writer.writerows(all_data)

        print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_csv}")

    finally:
        driver.quit()
